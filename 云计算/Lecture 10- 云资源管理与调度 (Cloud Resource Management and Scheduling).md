## 1. 资源管理的政策与机制 (Policies and Mechanisms for Resource Management)

### 1.1 资源管理的重要性

- 资源管理是任何人造系统的关键功能之一
- 所有系统都拥有有限资源，这些资源必须在不同系统组件间共享
- **Policy (政策)**: 指导决策的原则
- **Mechanism (机制)**: 实施政策的手段

### 1.2 资源管理影响的三个基本评估标准

资源管理直接影响三个系统评估的基本标准:

- **Functionality (功能性)**: 系统是否按照规范运行
- **Performance (性能)**: 系统是否满足设计的性能标准
- **Cost (成本)**: 建设和维护系统的成本是否符合规范

### 1.3 计算系统中的调度

- 计算系统中的调度主要决定如何分配系统资源
- 资源包括: CPU 周期、内存、二级存储空间、I/O 和网络带宽
- 这些资源需在用户和任务之间合理分配

## 2. 云资源管理的示例与挑战 (Challenges for Cloud Resource Management)

### 2.1 Cloud Café 示例

### 云咖啡馆场景设定

- Cloud Café 是一个云托管的虚拟咖啡店，用户通过app点咖啡
- 高峰时段(早上8点)，成千上万用户同时下单
- 夜间，几乎没有订单
- 每台咖啡机(虚拟机或容器)能处理 50 orders/minute
- 系统可以动态增减机器数量(类似云弹性)
- 咖啡店希望: 快速服务所有人(QoS)、保持成本低、无人时节能

### 示例中的挑战

- 如果10,000位用户同时到达，但只有5台机器运行?
- 如果一直保持1,000台机器运行? (快速但昂贵且浪费能源)
- 如果某台机器突然故障?

### 需要智能资源管理来:

- 预测需求
- 分配足够的机器
- 平衡负载
- 关闭未使用的机器
- 确保良好服务而不过度花费

### 2.2 云资源管理面临的挑战

- ==**复杂性挑战**==:
    - 需要多目标优化的复杂政策和决策
    - 受到不可预测的环境因素影响(如系统故障和攻击)
    - 面对大幅波动的负载，挑战云弹性宣称
- ==**有效管理的困难**====:
    - 云基础设施规模庞大，难以获取准确的全局状态信息
    - 与大量用户群体的交互，使得预测系统工作负载类型和强度几乎不可能
    - IaaS、PaaS和SaaS的资源管理策略各不相同

## 3. 云资源管理政策 (Cloud Resource Management Policies)

### 3.1 五类主要管理政策

1. **Admission Control (准入控制)**:
    - 防止系统接受违反高级系统目标的工作负载
    - 咖啡馆类比: "我们已满!" - 当客户过多时，停止接受新订单避免长等待时间
2. **Capacity Allocation (容量分配)**:
    - 为服务的个别激活分配资源
    - 咖啡馆类比: "你得到2名咖啡师和1台咖啡机" - 为每个订单分配适当资源
3. **Load Balancing (负载均衡)**:
    - 在服务器之间均匀分配工作负载
    - 咖啡馆类比: "引导下个客户到最短队列" - 在可用机器间均匀分配咖啡订单
4. **Energy Optimization (能源优化)**:
    - 最小化能源消耗
5. **Quality of Service Guarantees (服务质量保证)**:
    - 满足服务级别协议(SLA)规定的时间或其他条件的能力
    - 咖啡馆类比: "每位客户在2分钟内得到咖啡" - 满足快速服务、无错误的承诺

### 3.2 权衡取舍 (Tradeoffs)

- 性能和能源消耗之间存在权衡关系
- 当时钟频率降低时，性能下降率低于能源消耗下降率
- 为降低成本和节约能源，可能需要将负载集中在较少的服务器上，而非平衡分配

## 4. 云资源利用率与能源效率 (Cloud Resource Utilization and Energy Efficiency)

### 4.1 计算能耗增长趋势

- 计算能耗与计算设备数量成线性增长
- 根据摩尔定律，芯片上的晶体管数量每1.5年翻一番，计算能力相应增加
- 计算设备的电效率约每1.5年翻一番
- 云数据中心能耗不断增长，对生态环境有显著影响，也影响云服务成本

### 4.2 能源成本对云服务定价的影响

- 不同地区的云服务成本受能源成本影响明显
- 示例: AWS美国东部与南美地区成本比较
    - 前期成本: $2,604/年 vs $5,632/年
    - 小时成本: $0.412 vs $0.724
- 两地区40%的成本差异主要来自能源和通信成本差异

## 5. 云弹性与过度配置 (Cloud Elasticity and Overprovisioning)

### 5.1 云弹性 (Cloud Elasticity)

- **定义**: 当应用需要时保证分配额外资源，不需要时释放资源
- 用户只需为实际使用的资源付费
- 弹性基于过度配置和两个假设:
    - 存在有效的准入控制机制
    - 所有运行中应用同时大幅增加资源消耗的可能性极低

### 5.2 过度配置 (Overprovisioning)

- **定义**: 云服务提供商必须投资比典型云工作负载所需更大的基础设施
- 导致平均云服务器利用率低
- **问题**:
    - 低服务器利用率对每瓦性能(PWP)产生负面影响
    - 增加云计算的生态影响
    - 过度配置在经济上不可持续

## 6. 能源效率 (Energy Efficiency)

### 6.1 能耗与系统负载的关系

- 即使能耗需求与负载线性变化，计算系统的能源效率也不是负载的线性函数
- 即使在空闲状态，系统可能使用相当于满负载时50%的能耗
- 数据中心服务器的典型运行区域为负载的10%到50%

### 6.2 能源比例系统 (Energy-proportional Systems)

- **定义**: 一个能源比例系统在空闲时不消耗能源，轻负载时消耗很少能源，随负载增加而增加能耗
- 理想情况下，系统始终以100%效率运行
- **动态范围** (Dynamic Range) 由设备功耗的上下限决定
- 较大的动态范围意味着设备在低负载时能以较低比例的峰值功率运行

### 6.3 不同系统组件的能源效率

- 计算系统的不同子系统在能源效率方面表现不同
- 云服务器使用的处理器在很低负载时消耗不到峰值功率的1/3，动态范围超过峰值功率的70%
- 移动/嵌入式系统使用的处理器通常能效更好
- 例如: 2.4 GHz Intel Q6600处理器配4GB RAM，空闲时消耗110W，满载时消耗175W

### 6.4 节能策略 (Energy Saving)

- 替代"服务器始终开启"策略的方法是开发能源感知的负载均衡和扩展政策
- 这些政策结合动态电源管理与负载均衡，识别运行在非最佳能源状态的服务器
- 能源优化不能孤立考虑，必须与准入控制、容量分配、负载均衡和服务质量结合
- 目前机制难以支持所有政策的并发优化:
    - 基于控制理论的机制过于复杂且扩展性差
    - 基于机器学习的机制尚未完全发展
    - 其他机制需要对动态配置系统的建模

## 7. 资源管理与动态应用扩展 (Resource Management and Dynamic Application Scaling)

### 7.1 两种应用扩展策略

1. **垂直扩展 (Vertical Scaling)**:
    - 保持应用的VM数量不变，但增加分配给每个VM的资源量
    - 可通过两种方式实现:
        - 将VM迁移到更强大的服务器
        - 保持VM在同一服务器但增加CPU时间
    - 第一种方式涉及额外开销:
        - 停止VM
        - 创建VM快照
        - 将文件传输到更强大的服务器
        - 在新位置重启VM
2. **水平扩展 (Horizontal Scaling)**:
    - 随负载增加增加VM数量，负载减少时减少VM数量
    - 通常导致应用消耗的通信带宽增加
    - 运行中VM之间的负载均衡对这种运行模式至关重要

### 7.2 应用设计对扩展的影响

- 应用应设计为支持扩展
- **模块化可分应用** (Modularly Divisible Application): 工作负载分区是静态的
- **任意可分应用** (Arbitrarily Divisible Application): 工作负载可动态分区

## 8. 控制理论与最优资源管理 (Control Theory and Optimal Resource Management)

### 8.1 控制理论基础

- 控制理论提供数学框架，用于设计能调节自身行为的系统
- 在计算系统中，尽管工作负载和条件变化，仍维持期望的性能水平

### 关键概念:

- **反馈循环** (Feedback Loop): 系统监控输出并相应调整输入
- **稳定性** (Stability): 确保系统在受到干扰后回到期望状态
- **预测控制** (Predictive Control): 使用模型预测系统行为并计算最优操作

### 8.2 云计算中使用控制理论的原因

- 动态工作负载下自适应管理资源(CPU、内存、带宽)
- 确保QoS、能源效率和负载均衡
- 处理不确定性和干扰(如系统故障和流量突发)

### 8.3 控制理论在资源管理中的应用

- 控制理论用于设计多类应用的自适应资源管理:
    - 电源管理
    - 任务调度
    - Web服务器中的QoS调整
    - 负载均衡
- 经典反馈控制方法基于系统输出测量来调节关键操作参数

### 8.4 云控制系统的主要组件

- **输入**: 提供的工作负载和准入控制、容量分配、负载均衡、能源优化和QoS保证的政策
- **控制系统组件**:
    - 传感器: 用于估计相关性能指标
    - 控制器: 实施政策
- **输出**: 分配给各应用的资源

### 8.5 反馈与稳定性 (Feedback and Stability)

- **控制粒度** (Control Granularity): 用于控制系统的信息详细程度
    - **细粒度控制** (Fine Control): 使用非常详细的参数信息
    - **粗粒度控制** (Coarse Control): 用实施效率换取参数精度
- **稳定性** 与输出的变化有关，控制器使用传感器反馈稳定系统
- 任何控制系统不稳定的来源:
    - <font color="#ff0000">控制动作后获取系统反应的延迟</font>
	- <font color="#ff0000"> 控制粒度问题: 控制器的小变化导致输出的大变化</font>
	- <font color="#ff0000">振荡: 当输入变化过大而控制太弱，输入变化直接传播到输出</font>

### 8.6 云控制器结构

- 控制器使用当前状态反馈和对未来环境干扰的估计来计算有限时域内的最优输入
- 结构包括: 预测过滤器、最优控制器和排队动态
- r和s是性能指标的权重因子

## 9. 两级资源分配架构 (A Two-level Resource Allocation Architecture)

### 9.1 基本架构

- 自动资源管理基于两级控制器:
    - 服务提供商控制器
    - 应用控制器
- **输入**: 提供的工作负载和云中的各种政策(准入控制、容量分配等)
- **系统组件**: 用于估计性能指标的传感器和实施各种政策的控制器
- **输出**: 分配给各应用的资源
    
    ![[截屏2025-05-10_15.07.32.png]]
    

### 9.2 两级控制器的优势

- 有两种类型的控制器:
    - **应用控制器** (Application Controllers): 确定是否需要额外资源
    - **云控制器** (Cloud Controllers): 仲裁资源请求并分配物理资源
- 可选择细粒度或粗粒度控制
- 基于时间平均的动态阈值优于静态阈值
- 可使用高低两个阈值而非仅高阈值

### 9.3 两级实验的经验教训

- 控制系统的操作应有一定节奏，避免不稳定
- 只有在系统性能稳定后才应进行调整
- 如果设置了高低阈值，当它们太接近、工作负载变化足够大且适应所需时间不允许系统稳定时，会发生不稳定
- 操作包括分配/取消分配一个或多个虚拟机
- 有时一个阈值要求的单个VM分配/解除可能导致跨越另一阈值，这是不稳定的另一来源

## 10. 计算机云的调度算法 (Scheduling Algorithms for Computer Clouds)

### 10.1 云调度概述

- 调度负责多个层次的资源共享:
    - 服务器可在多个虚拟机间共享
    - 虚拟机可支持多个应用
    - 应用可包含多个线程
- 调度算法应高效、公平且无饥饿现象
- 调度器的目标:
    - **批处理系统**: 最大化吞吐量，最小化周转时间
    - **实时系统**: 满足截止时间，具可预测性

### 10.2 尽力而为 (Best-effort) 算法

- 适用于批处理应用和分析
- 常见尽力而为应用算法:
    - **Round-robin** (轮询)
    - **First-Come-First-Serve (FCFS)** (先到先得)
    - **Shortest-Job-First (SJF)** (最短作业优先)
    - **Priority algorithms** (优先级算法)

### 10.3 多媒体与实时应用调度

- **多媒体应用** (如音频和视频流):
    - 具有软实时约束
    - 要求统计保证的最大延迟和吞吐量
- **实时应用** 具有硬实时约束
- 实时应用的调度算法:
    - **Earliest Deadline First (EDF)** (最早截止期限优先)
    - **Rate Monotonic Algorithms (RMA)** (速率单调算法)
- 集成调度多类应用的算法:
    - **Resource Allocation/Dispatching (RAD)** (资源分配/调度)
    - **Rate-Based Earliest Deadline (RBED)** (基于速率的最早截止期限)

### 10.4 资源需求政策分类

- **尽力而为政策** (Best-effort Policies):
    - 不对分配给应用的资源量或调度时间施加要求
    - 时间和数量均为宽松要求
- **软需求政策** (Soft-requirements Policies):
    - 要求统计保证的资源量和时间约束
    - 时间为宽松要求，数量为严格要求
- **硬需求政策** (Hard-requirements Policies):
    - 要求严格的时间安排和精确的资源量
    - 时间和数量均为严格要求
    - 用于硬实时应用

## 总结 (Summary)

云资源管理是确保云计算系统有效运行的核心功能，涉及多种政策和机制来平衡功能性、性能和成本。主要挑战包括处理波动的工作负载、能源效率和服务质量保证。云弹性依赖于过度配置，但这带来了资源利用率低的问题。通过垂直和水平扩展策略，结合控制理论和两级资源分配架构，可以实现更有效的资源管理。调度算法根据不同应用类型(尽力而为、软实时、硬实时)的需求，采用不同的策略来优化资源使用。