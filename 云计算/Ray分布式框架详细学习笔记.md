# Ray分布式框架详细学习笔记

## 1. Ray基本介绍

Ray是一个为**新兴AI应用**设计的**分布式框架**，它能够满足现代AI应用对**性能和灵活性**的高要求。与传统的大数据框架不同，Ray特别针对强化学习(Reinforcement Learning, RL)等需要**训练(Training)、模拟(Simulation)和服务(Serving)** 紧密结合的AI工作负载进行了优化。

### 1.1 背景与动机

- 传统的分布式框架（如MapReduce, Spark, Dryad等）主要针对**批处理**工作负载设计
- 深度学习框架（如TensorFlow, MXNet等）主要专注于**模型训练**
- **强化学习**应用要求在**动态环境**中持续学习和反应，需要同时处理:
    - **模拟**(Simulation): 评估策略
    - **训练**(Training): 基于模拟数据改进策略
    - **服务**(Serving): 在交互式环境中应用策略

### 1.2 关键系统需求

1. **细粒度、异构计算**：任务执行时间从毫秒到小时不等，需要支持CPU、GPU等不同硬件
2. **灵活的计算模型**：需要同时支持无状态计算（适合模拟）和有状态计算（适合训练）
3. **动态执行**：计算顺序通常无法预先确定，计算结果会影响后续计算

## 2. Ray的编程模型与计算模型

### 2.1 编程模型 (Programming Model)

Ray提供两种主要抽象:

#### 2.1.1 **Task-based模型**(任务模型)

- 通过`@ray.remote`装饰器定义远程函数
- 调用远程函数返回future对象
- 任务是**无状态的**(stateless)，相同输入产生相同输出
- 可以使用`ray.get()`获取结果，使用`ray.wait()`等待完成

#### 2.1.2 **Actor-based模型**(参与者模型)

- 通过`@ray.remote`装饰类来定义actor
- Actor是**有状态的**(stateful)，可以维护内部状态
- Actor方法按顺序执行，保持状态一致性
- 可以通过传递Actor引用让不同组件交互

#### 2.1.3 任务与Actor对比

表格

|**Tasks (无状态)**|**Actors (有状态)**|
|---|---|
|细粒度负载均衡|粗粒度负载均衡|
|支持对象局部性|局部性支持较差|
|小更新开销大|小更新开销低|
|高效故障处理|需要检查点机制|

### 2.2 计算模型 (Computation Model)

Ray实现了**动态任务图计算模型**(Dynamic Task Graph)：

- **数据对象**和**任务调用**构成计算图节点
- 图中包含三种边:
    - **数据边**(Data edges): 表示数据对象与任务间的依赖关系
    - **控制边**(Control edges): 表示嵌套远程函数调用产生的计算依赖
    - **状态边**(Stateful edges): 表示同一Actor上连续方法调用之间的状态依赖

## 3. Ray系统架构

Ray的架构分为两层:

### 3.1 应用层 (Application Layer)

- **Driver**: 执行用户程序的进程
- **Worker**: 无状态进程，执行远程函数（任务）
- **Actor**: 有状态进程，执行其暴露的方法

### 3.2 系统层 (System Layer)

#### 3.2.1 **全局控制存储**(Global Control Store, GCS)

- Ray的**核心创新点**之一
- 存储系统的全部控制状态（如任务、对象、线性依赖等）
- 使用**分片**(sharding)实现水平扩展
- 通过**链式复制**(chain replication)提供容错能力
- **去耦设计**: 将控制平面信息存储与逻辑实现分离

#### 3.2.2 **自下而上分布式调度器**(Bottom-Up Distributed Scheduler)

- 两级层次结构:
    - **本地调度器**(Local Scheduler): 优先在本地节点调度任务
    - **全局调度器**(Global Scheduler): 处理本地无法满足的任务
- 避免中央调度器瓶颈，实现**毫秒级**调度延迟
- 调度决策考虑节点负载、任务约束和数据位置

#### 3.2.3 **内存分布式对象存储**(In-Memory Distributed Object Store)

- 存储任务的输入和输出
- 通过**共享内存**实现零拷贝数据共享
- 只支持**不可变对象**，简化一致性和容错支持
- 使用**LRU策略**在内存不足时将对象驱逐到磁盘

## 4. Ray关键特性

### 4.1 **编程模型统一**

- 首次将task-parallel和actor-based编程模型统一在单一框架中
- 允许开发者根据需求选择合适的抽象

### 4.2 **高性能与低延迟**

- 能够调度**每秒数百万任务**
- 任务调度和执行延迟在**毫秒级**
- 对象存储提供高吞吐率：大对象>15GB/s，小对象>18K IOPS

### 4.3 **容错性**

- 对任务采用**基于谱系的容错**(lineage-based fault tolerance)
- 对Actor采用**基于检查点的恢复**(checkpoint-based recovery)
- 对GCS采用**基于复制的容错**(replication-based fault tolerance)

### 4.4 **动态工作负载支持**

- 异构任务执行时间
- 支持动态构建任务图
- 使用`ray.wait()`支持动态完成任务

### 4.5 **水平扩展性**

- GCS分片架构支持系统线性扩展
- 分布式调度器避免单点瓶颈
- 分布式对象存储实现数据并行访问

## 5. Ray与强化学习的关系

### 5.1 强化学习基本流程

1. **策略评估**(Policy Evaluation): 通过模拟环境与策略交互生成轨迹
2. **策略改进**(Policy Improvement): 使用收集的轨迹更新策略

### 5.2 Ray如何支持强化学习

#### 5.2.1 **训练**(Training)

- 使用Actor实现参数服务器或模型副本
- 支持分布式SGD进行策略更新
- 比专用系统(如Horovod和分布式TensorFlow)性能相当

#### 5.2.2 **服务**(Serving)

- 低延迟策略服务，实现高吞吐量决策
- 嵌入式服务性能超过专用系统Clipper
- 在同一应用中无缝集成策略服务

#### 5.2.3 **模拟**(Simulation)

- 高效处理可变长度、异构模拟任务
- 动态收集模拟结果，避免全局同步障碍
- 比基于MPI的同步实现提供更高吞吐量

## 6. Ray关键算法实现

### 6.1 **Evolution Strategies (ES)**

- Ray实现可扩展到8192个核心
- 使用Actor树实现层次聚合
- 比专用系统表现更好，解决驱动进程瓶颈

### 6.2 **Proximal Policy Optimization (PPO)**

- Ray实现性能超过优化的MPI版本
- 充分利用异构资源(CPU和GPU)
- 通过资源感知调度降低成本

## 7. Ray与其他系统比较

### 7.1 与动态任务图系统比较 (CIEL, Dask)

- Ray提供Actor抽象支持有状态计算
- Ray实现完全分布式和解耦的控制平面和调度器

### 7.2 与数据流系统比较 (Spark, MapReduce, Dryad)

- Ray支持**细粒度**和**动态**任务图
- Ray不受限于BSP(批量同步并行)执行模型

### 7.3 与机器学习框架比较 (TensorFlow, MXNet)

- Ray支持更通用的计算(不限于静态线性代数DAG)
- Ray能够紧密集成训练、模拟和服务

### 7.4 与Actor系统比较 (Orleans, Akka)

- Ray提供透明的故障恢复机制
- Ray支持精确一次(exactly-once)语义
- Ray同时支持无状态任务和有状态Actor

## 8. Ray的技术优势

### 8.1 **去中心化设计**

- 将控制状态(GCS)与控制逻辑(调度器)分离
- 允许存储和计算层独立扩展

### 8.2 **自下而上的调度策略**

- 优先本地调度，减少全局调度器压力
- 全局调度器考虑数据位置和负载均衡

### 8.3 **共享内存对象存储**

- 任务间零拷贝数据共享
- 高效处理大对象和小对象

### 8.4 **透明容错**

- 自动重建丢失对象
- Actor从最近检查点恢复

## 总结

Ray是一个为新兴AI应用设计的通用分布式框架，其最大的创新是统一了**task-based**和**actor-based**编程模型，并通过全局控制存储(GCS)和分布式调度器实现了高性能和容错性。Ray特别适合强化学习等需要训练、模拟和服务紧密结合的AI工作负载，通过提供毫秒级任务调度和每秒百万任务吞吐量，满足了现代AI应用的性能需求。

Ray的**主要编程模型**是结合了**Actor-based和Task-based编程模型**，这使其能够同时支持有状态计算(如训练)和无状态计算(如模拟)，为强化学习等AI应用提供了理想的框架。