Question 1 (1 point) Saved

Which feature makes Ray suitable for reinforcement learning applications?

- ﻿﻿<font color="#ff0000">Asynchronous task execution and actor-based parallelism</font>
- ﻿﻿Efficient gradient computation using GPU clusters
- ﻿﻿Built-in support for dynamic model training
- ﻿﻿Pre-trained reinforcement learning models for different tasks
- ﻿﻿Low-latency model inference using TensorRT
- ﻿﻿Automated hyperparameter tuning

Question 2 (1 point) v Saved

How does Ray minimize scheduling overhead?

- ﻿By executing all tasks in a fixed priority order
- ﻿﻿By assigning tasks to specific hardware manually
- ﻿By using hardware-based scheduling acceleration
- ﻿﻿By reducing the number of worker nodes dynamically
- ﻿﻿By running tasks sequentially instead of in parallel
- ﻿﻿<font color="#ff0000">By using a decentralized scheduler that minimizes central bottlenecks</font>

Question 3(1 point) ~ Saved

What component in Ray is responsible for managing distributed task execution?

- ﻿﻿The Cluster State Manager
- ﻿﻿The Al Execution Engine
- ﻿The Ray Trainer Module
- ﻿﻿The Ray Master Node
- ﻿﻿<font color="#ff0000">The Global Control Store (GCS)</font>
- ﻿The Ray Client |

Question 4 (1 point) v Saved

How does Ray support failure recovery in distributed computing?

- ﻿By requiring manual intervention to handle failures
- ﻿﻿By maintaining a checkpoint-based rollback system
- ﻿﻿By storing all intermediate results on a shared file system
- <font color="#ff0000">﻿﻿By using lineage-based fault tolerance to recompute lost tasks</font>
- ﻿By restarting the entire computation in case of failure
- ﻿﻿By relying on external Kubernetes-based recovery mechanisms

Question 5 (1 point) v Saved

What is the primary goal of the Ray framework?

- ﻿To offer a cloud-based service for GPU-based computations
- ﻿﻿To replace Kubernetes for container orchestration
- ﻿﻿<font color="#ff0000">To support distributed execution of Al and machine learning applications</font>
- ﻿To provide a specialized deep learning framework for neural networks
- ﻿﻿To provide a real-time streaming system for loT data processing
- ﻿﻿To optimize traditional batch processing for big data analytics

Question 6 (1 point) v Saved

How does Ray achieve scalability?

- ﻿By pre-allocating resources before execution
- ﻿By statically assigning workloads to worker nodes
- ﻿﻿By using a centralized master node for all scheduling decisions
- ﻿By relying on high-speed distributed storage
- ﻿By running on specialized Al hardware
- ﻿﻿<font color="#ff0000">By using a lightweight, decentralized scheduling model</font>

Question 7 (1 point) ~ Saved

What type of workloads can be efficiently executed using Ray?

- ﻿﻿Blockchain transaction processing
- ﻿﻿<font color="#ff0000">Distributed Al applications, including reinforcement learning and hyperparameter tuning</font>
- ﻿﻿SQL query optimization
- ﻿﻿Web-based microservices
- ﻿﻿Traditional batch processing for large-scale databases
- ﻿Real-time streaming for loT networks

Question 8(1 point) Saved

What are the two primary abstractions in Ray's execution model?

- ﻿﻿Pipelines and queues
- ﻿﻿Graphs and nodes
- ﻿﻿<font color="#ff0000">Actors and tasks</font>
- ﻿﻿Microservices and containers
- ﻿﻿Streams and buffers
- ﻿﻿Threads and processes

Question 9 (1 point) v Saved

Which of the following is NOT a key feature of Ray?

- ﻿﻿Actor-based execution for dynamic workloads
- ﻿﻿Automatic scheduling of machine learning training jobs
- ﻿﻿Fault-tolerant task execution
- ﻿﻿<font color="#ff0000">Direct execution of SQL queries on large datasets</font>
- ﻿﻿Support for heterogeneous computing environments
- ﻿﻿Built-in distributed reinforcement learning support

Question 10 (1 point) v Saved

What programming model does Ray primarily use?

- A purely synchronous execution model
- A stateful streaming model
- ﻿﻿MPI-based parallel processing
- ﻿﻿MapReduce-based distributed execution
- ﻿﻿SQL-based query execution
- <font color="#ff0000">﻿﻿Actor-based and task-based programming models</font>

Question 11 (1 point) / Saved

What is a key difference between Ray's actor-based model and its task-based model?

- ﻿﻿<font color="#ff0000">Actors maintain state across method calls, while tasks do not</font>
- ﻿﻿Tasks are scheduled in advance, while actors are scheduled dynamically
- ﻿﻿Actors execute only once, while tasks can be reused
- ﻿﻿Actors operate only on local data, while tasks can handle distributed data
- ﻿﻿Tasks can only run on CPUs, while actors require GPUs
- ﻿﻿Tasks run asynchronously, while actors are always synchronous

Question 12 (1 point) v Saved

Why is Ray particularly useful for Al applications compared to traditional distributed computing frameworks?

- ﻿﻿<font color="#ff0000">It is optimized for iterative and dynamic workloads commonly found in Al applications</font>
- ﻿﻿It offers native support for running Al applications on blockchain networks
- ﻿﻿It prioritizes power efficiency over computational speed
- ﻿﻿It requires minimal memory to run distributed computations
- ﻿﻿It provides direct integration with high-performance databases
- ﻿It replaces all functionalities of TensorFlow and PyTorch

Question 13 (1 point) Saved

Which key challenge does Ray aim to address?

- ﻿Developing new neural network architectures
- <font color="#ff0000">﻿﻿Efficient distributed computing for heterogeneous Al workloads</font>
- ﻿﻿The high cost of cloud-based Al training
- ﻿﻿Improving memory bandwidth in GPUs
- ﻿Reducing the energy consumption of Al models
- ﻿﻿Replacing MapReduce for data processing

Question 14 (1 point) v Saved

How does Ray handle distributed task scheduling?

- ﻿Using a centralized job queue processed sequentially
- ﻿﻿By relying on manual assignment of tasks to nodes
- ﻿﻿Through a static task allocation plan
- ﻿By using a round-robin scheduling algorithm
- ﻿﻿<font color="#ff0000">Through a decentralized scheduler with lightweight task submission</font>
- ﻿By executing tasks on a single master node

Question 15 (1 point) v Saved

What is a major advantage of Ray's actor model for distributed AI workloads?

- ﻿﻿It simplifies deployment of Al models on mobile devices
- ﻿﻿It guarantees strict sequential execution of Al tasks
- ﻿﻿<font color="#ff0000">It allows for stateful computations that persist across function calls</font>
- ﻿﻿It eliminates the need for inter-node communication
- ﻿﻿It restricts computations to predefined scheduling policies