  

## 1. 云计算时代的数据存储 (Data Storage in the Age of Cloud Computing)

### 1.1 数据增长与存储需求

- 人类活动产生的数据量**每年增长约40%** (growing by about 40% per year)
- 当今世界上90%的数据是在过去两年中收集的 (90% of the data in the world today has been gathered in the last two years)
- **网络中心数据存储模型** (network-centric data storage model) 对于电量和本地存储有限的移动设备特别有用
- 这些设备现在能够存储和访问保存在计算机云上的大型音频和视频文件 (large audio and video files stored on computer clouds)

### 1.2 大数据的现实 (Big Data Reality)

- **Big Data** 反映了许多应用程序使用的数据集非常大，以至于本地计算机或中小型数据中心没有能力存储和处理此类数据
- 大数据的三个维度 (Three-dimensional phenomena):
    - 数据量增加 (Increased volume of data)
    - 需要更快的处理速度 (Increased processing speed)
    - 涉及多样化的数据源和数据类型 (Diversity of data sources and data types)

### 1.3 大数据应用实例

- 2010年，大型强子对撞机(LHC)的四个主要探测器产生了13 PB的数据
- 其他应用领域：基因组学、结构生物学、高能物理学、天文学和气象学等，这些领域处理的数据集通常在TB级别

## 2. 存储系统的主要挑战 (Major Challenges)

### 2.1 设计理念转变

- 存储系统设计理念从"不惜任何代价追求性能"转变为"以尽可能低的成本实现可靠性" (from performance-at-any-cost to reliability-at-the-lowest-possible-cost)
- 这种设计理念对软件复杂性有重要影响

### 2.2 具体挑战

- **一致性维护** (Maintaining consistency)：在多个数据记录副本之间保持一致性增加了数据管理软件的复杂性
- **访问时间策略** (Access time strategies)：需要复杂策略来减少访问时间并支持多媒体访问，以满足数据流和内容交付的时间要求
- **数据复制** (Data replication)：允许多个处理器并发访问数据，并减少数据丢失的可能性

## 3. 存储技术与数据模型 (Storage Technologies and Data Models)

### 3.1 存储技术的演变 (Evolution of Storage Technology)

### 3.1.1 动态随机存取存储器 (Dynamic Random Access Memory, DRAM)

- 1990-2003年期间：
    - 密度从约1 Gb/in²增加到100 Gb/in²
    - 成本从约$80/MB下降到不到$1/MB

### 3.1.2 硬盘驱动器 (Hard Disk Drives, HDD)

- 1980-2003年期间：
    - 存储密度增加了四个数量级，从约0.01 Gb/in²到约100 Gb/in²
    - 价格下降了五个数量级，约为1美分/MB
    - HDD密度预计将从2011年的744 Gb/in²攀升至2016年的1,800 Gb/in²

### 3.1.3 固态硬盘 (Solid-State Disk, SSD)

- 接口与HDD的块I/O兼容，可替代传统磁盘
- 没有移动部件，通常更抵抗物理冲击
- 运行安静，访问时间更短，延迟低于HDD

### 3.1.4 混合固态硬盘 (Solid-State Hybrid Disks, SSHD)

- 结合SSD和HDD的特点
- 包括大型HDD和SSD缓存，以提高频繁访问数据的性能

### 3.1.5 企业级闪存驱动器 (Enterprise Flash Drives, EFDs)

- 具有更高规格的SSD，设计用于需要高I/O性能(IOPS)的应用程序
- 包括控制器和嵌入式处理器，对EFD性能至关重要
- 执行固件级代码，如读写缓存、加密、错误检测和纠正以及垃圾收集

### 3.2 存储和数据模型概述

- **存储模型** (Storage model): 描述数据结构在物理存储中的布局
- **数据模型** (Data model): 捕获数据库中数据结构最重要的逻辑方面

### 3.3 两种抽象存储模型

### 3.3.1 单元存储 (Cell Storage)

- 假设存储由**相同大小的单元**组成，每个对象恰好适合一个单元
- 反映了几种存储媒体的物理组织：
    - 计算机的主存储器组织为存储单元阵列
    - 辅助存储设备（如磁盘）以扇区或块为单位组织，作为一个单位读写
- 两个高度期望的属性：
    - **读/写一致性** (Read/Write coherence): 从存储单元M读取的结果应该与最近对该单元的写入相同
    - **前后原子性** (Before-or-after atomicity): 每次读取或写入的结果与该读取或写入完全在任何其他读取或写入之前或之后发生的结果相同

### 3.3.2 日志存储 (Journal Storage)

- 一个在日志中跟踪变更的系统
- 包括管理器和单元存储，维护变量的整个历史记录而不仅仅是当前值
- 系统崩溃或断电后可以更快地恢复在线状态，且不太可能被损坏
- 用户不能直接访问单元存储，而是请求日志管理器执行以下操作：
    1. 启动新操作 (Start a new action)
    2. 读取单元值 (Read the value of a cell)
    3. 写入单元值 (Write the value of a cell)
    4. 提交操作 (Commit an action)
    5. 中止操作 (Abort an action)

### 3.4 存储系统日志 (Log of a Storage System)

- 包含单元存储中所有变量的历史记录
- 关于每个数据项更新的信息形成一条记录，附加到日志末尾
- 提供有关涉及单元存储的操作结果的权威信息
- 可以使用日志重建单元存储，日志可以轻松访问

## 4. Google文件系统 (Google File System, GFS)

### 4.1 文件的逻辑和物理组织

- **文件** (File): 存储在持久存储设备上的单元的线性数组
- 应用程序将其视为逻辑记录的集合，存储在物理设备上
- **文件指针** (File pointer) 标识用作读取或写入操作起点的单元
- **逻辑组织** (Logical organization) 反映数据模型，即应用程序角度的数据视图
- **物理组织** (Physical organization) 反映存储模型，描述文件在给定存储媒体上的存储方式

### 4.2 GFS简介与挑战

- 开发于1990年代末；使用由廉价商用组件构建的数千个存储系统，为具有多样化需求的大型用户社区提供PB级存储
- 主要挑战:
    - **性能** (Performance) → 数据分片 (Sharding) (将数据分布在数百台服务器上)
    - **故障** (Faults) → 容错性 (Tolerance)
    - **容错性** (Tolerance) → 复制 (Replication)
    - **复制** (Replication) → 不一致性 (Inconsistency)
    - **一致性** (Consistency) → 低性能 (Low performance)

### 4.3 GFS设计考虑因素

- **可扩展性和可靠性** (Scalability and reliability) 是系统的关键特性，必须从一开始就考虑
- 绝大多数文件的大小从几GB到数百TB不等，如网络爬虫、YouTube等
- 最常见的操作是**追加**到现有文件；随机写入操作极为罕见
- **顺序读取**操作是常态
- 用户批量处理数据，对响应时间的关注较少
- 一致性模型应该放宽，以简化系统实现，同时不给应用程序开发人员带来额外负担

### 4.4 GFS的设计决策

- 将文件分割成**大块** (large chunks)
- 实现**原子文件追加操作** (atomic file append operation)，允许多个并发运行的应用程序追加到同一个文件
- 围绕**高带宽**而非低延迟的互连网络构建集群
- 将控制流与数据流分离；通过TCP连接**流水线数据传输**以减少响应时间
- 利用**网络拓扑**，将数据发送到网络中最近的节点
- 消除客户端的**缓存** (caching)，因为缓存增加了维护缓存副本之间一致性的开销
- 通过将关键文件操作引导到**主服务器** (master) 来确保一致性
- 最小化主服务器在文件访问操作中的参与，以避免热点争用并确保可扩展性
- 支持高效的**检查点** (checkpointing) 和快速恢复机制
- 支持高效的**垃圾收集** (garbage collection) 机制

### 4.5 GFS架构

- GFS集群由一个主服务器和多个块服务器组成，由多个客户端访问
- 文件被分成固定大小的**块** (chunks)，每个块由主服务器在创建时分配的不可变且全局唯一的64位块句柄标识
- 块服务器将块作为Linux文件存储在本地磁盘上
- **主服务器** (master) 的职责:
    - 维护所有文件系统元数据，包括命名空间、访问控制信息、文件到块的映射以及块的当前位置
    - 控制系统范围的活动，如块租约管理、孤立块的垃圾收集和块服务器之间的块迁移
    - 通过**心跳消息** (HeartBeat messages) 与每个块服务器定期通信，以发出指令并收集其状态

### 4.6 GFS的块 (Chunks)

- GFS文件是固定大小的段（称为块）的集合
- 块大小为**64 MB**，这一选择是为了优化大文件的性能并减少系统维护的元数据量
- 大块大小增加了多个操作指向同一块的可能性，从而减少了定位块的请求数量
- 块存储在Linux文件系统上，并在多个站点上复制；用户可以将副本数量从标准的三个更改为任何所需的值
- 每个块在文件创建时分配一个唯一的块句柄

### 4.7 操作日志 (Operation Logs)

- 操作日志包含关键元数据更改的历史记录，对GFS至关重要
- 它不仅是元数据的唯一持久记录，还作为定义并发操作顺序的逻辑时间线
- 它被复制到多个远程机器上，只有在将相应的日志记录刷新到本地和远程磁盘后才响应客户端操作
- 主服务器通过重放操作日志来恢复其文件系统状态
- 为最小化启动时间，必须保持日志较小；当日志增长超过特定大小时，主服务器会检查点其状态

### 4.8 一致性 (Consistency)

- 数据变更后文件区域的状态取决于变更类型、是否成功以及是否有并发变更
- 如果所有客户端无论从哪个副本读取都能看到相同的数据，则文件区域是**一致的** (consistent)
- 如果文件区域在数据变更后是一致的，且客户端将看到变更的全部内容，则该区域是**已定义的** (defined)
- 当变更在没有并发写入干扰的情况下成功时，受影响的区域是已定义的（且隐含一致）
- 并发成功的变更使区域**未定义但一致** (undefined but consistent)：所有客户端看到相同的数据，但它可能不反映任何一个变更所写入的内容

### 4.9 复制 (Replication)

- GFS集群在多个层次上高度分布：通常有数百个块服务器分布在多个机架上
- 这些块服务器可能被来自相同或不同机架的数百个客户端访问
- 不同机架上两台机器之间的通信可能跨越一个或多个网络交换机
- 块副本放置策略有两个目的：
    - 最大化数据可靠性和可用性
    - 最大化网络带宽利用率
- 仅仅在机器之间分散副本是不够的；还必须在机架之间分散块副本

### 4.10 容错性 (Fault Tolerance)

- 设计系统的最大挑战之一是处理频繁的组件故障；组件的质量和数量使这些问题成为常态而非例外
- 每个块在不同机架的多个块服务器上复制；用户可以为文件命名空间的不同部分指定不同的复制级别；默认为三个
- 主服务器状态为可靠性而复制；其操作日志和检查点复制到多台机器上
- 只有在其日志记录已刷新到本地磁盘和所有主服务器副本上后，对状态的变更才被视为已提交

## 5. 总结与关键点

### 5.1 云存储的关键特性

- 高可扩展性和可靠性
- 容错设计
- 高效的数据复制
- 针对大文件优化
- 支持顺序读取和追加操作

### 5.2 GFS的创新点

- 大块设计 (64MB)
- 主/块服务器架构
- 操作日志和检查点机制
- 放宽一致性模型以提高性能
- 高度分布式设计

### 5.3 考试重点概念

- **Data-intensive computing**: 处理大量数据的计算方式，从MB到PB级别
- **Storage models**: Cell storage vs. Journal storage
- **Read/Write coherence**: 读取结果应与最近写入相同
- **Before-or-after atomicity**: 操作效果应该是在其他操作之前或之后完全执行
- **GFS architecture**: 一个主服务器和多个块服务器的组合
- **Chunks**: GFS中文件的基本存储单位 (64MB)
- **Operation logs**: GFS中元数据变更的历史记录
- **Consistency models**: GFS中的一致性定义和保证

这些概念对于理解现代云存储系统和大数据处理基础设施至关重要，是考试的重点内容。